---
layout: page-with-sidebar-math
title:  "Filter往事(一)站在巨人的肩膀上"
date:   2023-11-21 10:47:03 +0800
author: reflectt6
categories: "大数据"
#permalink: 
mainTag: "大数据"
secondaryTag: "预研"
---

## 序

Bloom Filter也许很多人都知道，原理也很简单，实现起来更是简单。之前我对此也不以为然，好像也就是一个平平无奇的算法。后来听了教练组的一节课，才发现我们以为平平无奇的东西，只是因为我们站在了巨人的肩膀上。而巨人又站在别的巨人的肩膀上，于是我们越走越远。

有人单靠一手Bloom FIlter走到了教授的位置，现如今Bloom Filter的变种，以及各种优化版本已经数不胜数，形成了一个专门的研究分类，也出现了越来越复杂的新版FIlter。我研究FIlter也就两个月，不指望能有多高的造诣，只当是拾人牙慧好了。



## Cardinality 问题

计算机最古老的问题之一；给你一个数和一个集合，查询这个数被添加到了这个集合多少次

有比较著名的算法 `Count-min sketch`、`Counting Bloom Filter`。但不在本次讨论范围内。



## Membership Query 问题

计算机最古老的问题之一；给你一个数和一个集合，查询这个数在不在这个集合中。

最初的解决方案（naive approach）：存储所有数

可以使用以下数据结构：

1、List：$$O(1)$$插入、$$O(n)$$删除、$$O(n)$$查询

2、Sorted List：$$O(n)$$插入、$$O(n)$$删除、$$O(logn)$$查询

3、二叉搜索树（AVL、RB）：$$O(logn)$$插入、$$O(logn)$$删除、$$O(logn)$$​查询

有[论文](https://dl.acm.org/doi/10.1145/322261.322274)证明了二叉树更优

或使用hash映射，下面主要探讨各种hash的特点与优劣。

### Hash桶

通过hash将key映射到不同的桶中，实现上把key直接存储到对应的桶中。hash冲撞的概率直接影响效率，在最坏情况下，所有key都被映射到一个桶中，此时查询、插入、删除都退化成最初的解决方案，甚至每个桶内可以自成一个二叉搜索树。可以说兼具了初始方案优点的同时，通过分组进一步减小了查询时间。

`上面的解决思路是没有错误率的，也就是查询、插入、删除的结果一定是正确的！`

`但在缓存等场景，其实我们可以允许存在False Positive（假阳率），但是不允许Flase negative（假阴率）。因此有诞生了以下Filter`



### Hash桶->演化一（FingerPrint）

最初版本的Hash桶里面存着的是key本身，但是现在我们考虑将key映射到（1～m）的集合中，小于等于m的数都可以用$$(log_2m)$$位表示其二进制数。假设我们插入n个key，那么fingerPrint版本的 space 开销为$$n(log_2m)$$。

而Hash桶的空间开销为 $$nm$$ ，看得出来哈，通过FingerPrint，我们成功减小了空间开销，当然也引入了错误率。只有当两个key的Hash值出现碰撞时，我们才会出现错误场景（False Positive）。

对于计算方面，每一次操作前，多了一个Hash计算，其他并没有变。计算量小幅度增加。

`总结：通过fingerPrint的引入，我们进入了 概率数据结构（Probabilistic Data Structure）的领域（realm）。`



### FingerPrint的更优解 -> Bitmap

关于FingerPrint，更天才的做法是使用位图。

我们考虑将key映射到（1～m）的集合中，那我们就准备一个长为m的位图，当添加key时，就把key对应的Hash值当成位图的下标，将下标对应的位 置为1。

这样space开销为 $$m$$

计算FP:

在查询key时，有多大的概率出现Hash碰撞。也就是有多大的概率，明明这个key没有被插入过，但是其对应的位图上已经被置为1。

假设本次查询的key的hash值为t。位图已经插入了n个不同于key的数。位图长度为m。

1、第一次插入，没有插到t位置的概率为$$(1- {1 \over m})$$

2、第n次插入，没有插到t位置的概率为$$(1- {1 \over m})^n$$​

$(1- {1 \over m})^n$

 = $ (1- {1 \over m})^{m * {n \over m}}$ 

= $((1- {1 \over m})^m) ^ {n \over m}$

令：$y = (1- {1 \over m})^m$

1️⃣ 两边取对数：$ ln(y) = ln((1- {1 \over m})^m) = m*ln(1-{1 \over m})$

泰勒展开：$ln(1-{1 \over m}) = -{1 \over m} + {1 \over 2m^2} - {1 \over 3m^3} + ...$

带入1️⃣，得到：$ln(y) = -{1} + {1 \over 2m} - {1 \over 3m^2} + ...$

当m趋于无穷大，高阶项可以被忽略，因此 $\lim\limits_{m→∞} ln(y) \approx -1$

于是：$\lim\limits_{m→∞} y \approx e^{-1}$

于是：$\lim\limits_{m→∞} (1- {1 \over m})^m \approx e^{-1}$

于是：$\lim\limits_{m→∞} ((1- {1 \over m})^m)^{n \over m} \approx (e^{-1})^{n \over m}$

于是：$\lim\limits_{m→∞} (1- {1 \over m})^n \approx e^{ - {n \over m}}$



于是我们得出 $FP \approx 1- e^{ - {n \over m}}$





## [XOR Filter](https://arxiv.org/abs/1912.08258)

XOR的发音：`/ɛks ˈɔː(ɹ)/` 或 `/ˈzɔː(ɹ)/`，hvv讲师会读第二个发音。

业界如Lindorm，曾将Bloom Filter替换为Ribbon Filter提升缓存命中率。Ribbon Filter是由Xor Filter优化而来。所以Xor Filter需要作为前置条件理解一下。

但是看了知乎、CSDN好几篇帖子，写的相当抽象，我就不给引用了。说他们写的不认真吧，还画了很多图；说他们写的认真吧，细节很多错误；并且很多段落是一样的，感觉都是互相抄的；理解上的易错点也没有讲出来，看完还是云里雾里的。

无奈Google到了[论文](https://arxiv.org/pdf/1912.08258.pdf)，自己啃一遍吧。啃论文是真不容易，但是啃完也是能懂得。主要是结合伪代码理解，豁然开朗。突然想到某人说的，`talk is cheap，show me the code`，所以就是说这些论文在bb什么，直接给代码不就完事了吗。。

几个理解上的关键难点：

### 论文里面那些符号怎么理解？

![image-20231121160157285](/assets/images/2023-11-21-过滤器优化//image-20231121160157285.png)

> U：表示所有可能作为Filter输入的元素
>
> S：表示你要对哪一个集合构建过滤器，Bloom过滤器需要提前构造，需要把已知的数据映射到过滤器中。这个提前构造可能很多人没概念。
>
> \|S\|：目标集合的大小
>
> B：Xor过滤器最终存在形态就是这么一个数组，数组里面存的是k位的数值
>
> c = \|B\|：过滤器的长度，论文建议长度由(1.23*\|S\|)+23计算得来
>
> fingerprint：也是个hash函数，可以将U中任意元素，映射为一个固定长度为k位的数值。实现上可以参考：比如把任意元素分成三组，3的机器码为11，因此你总可以得到固定长度为2位的数值。例如1对应01，2对应10，3对应11。
>
> h1、h2、h3:三个hash函数，分别将U中的元素映射到[0, c/3]、[c/3, 2c/3]、[2c/3, c]

### 如何构造Xor FIlter

主要看以下三个伪代码：Algorithm2、3、4

![image-20231121163234079](/assets/images/2023-11-21-过滤器优化//image-20231121163234079.png)

下面这个Algorithm 3 有几率失败。

![image-20231121163506675](/assets/images/2023-11-21-过滤器优化//image-20231121163506675.png)

论文给出了失败的概率统计

![image-20231121163601434](/assets/images/2023-11-21-过滤器优化//image-20231121163601434.png)

![image-20231121163643314](/assets/images/2023-11-21-过滤器优化//image-20231121163643314.png)

### 如何判断元素是否存在？

![image-20231121163727997](/assets/images/2023-11-21-过滤器优化//image-20231121163727997.png)

### 为什么这样的算法可以用来判断元素存在？

首先我们需要了解异或运算本身的性质

异或运算有：

1、交换律

2、结合律

3、两个相同数xor的结果总为0

4、任何数和0 xor总为数本身

Algorithm2、3、4这三个算法保证了：

`对于任意的数x, B[h0(x)]、B[h1(x)]、B[h2(x)]中有且仅有一个apply了Algorithm4中的下面的赋值语句`

至于为什么能保证，请结合算法本身理解，这一部分的理解可以参考[知乎里面的图解](https://zhuanlan.zhihu.com/p/543943112)

![image-20231121165802686](/assets/images/2023-11-21-过滤器优化//image-20231121165802686.png)

假如只有B[h0(x)] apply 了上面的赋值语句，也就是i=h0(x)的情况，有 

`B[h0(x)] xor B[h1(x)] xor B[h2(x)] `

 `= `

 `(fingerprint(x) xor B[h0(x)] xor B[h1(x)] xor B[h2(x)]) `

`xor B[h1(x)]`

`xor B[h2(x)]`

`=`

`fingerprint(x) xor B[h0(x)] xor B[h1(x)] xor B[h2(x)] xor B[h1(x)] xor B[h2(x)]`

`=`

`fingerprint(x) xor B[h0(x)]`

`=fingerprint(x)    #由于i=h0(x)，所以B[h0(x)]被赋值为0；`



