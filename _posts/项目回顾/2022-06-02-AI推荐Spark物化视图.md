---
layout: page-with-sidebar
title:  "AI推荐Spark物化视图"
date:   2022-06-02 11:47:03 +0800
author: reflectt6
categories: "项目回顾"
mainTag: "项目回顾"
secondaryTag: "公司项目"
---

## 简介

开始之前，先讲讲什么是物化视图。知乎上有篇[文章](https://zhuanlan.zhihu.com/p/484146629)，基本上可以解答新人的所有疑惑。物化视图就是被实际存储起来的视图。

Spark（本文中的spark均指代spark sql）是不支持物化视图的，它仅支持创建临时视图。

## 项目背景

通过知乎上这边帖子可以得到，物化视图的几个关键性的难点：

1. 选择哪些数据进行物化
2. 当原始表更新时候，如何更新物化视图
3. 在用户查询时，如何对用户的查询进行改写

对以上难点进行分析，针对性给出解决方案：

1. 选哪些数据进行物化一定是从历史使用中分析出来了，于是我们设计了Spark日志解析模块，用来将历史运行的spark sql已经对应的执行计划都归纳出来，然后利用强化学习算法对其进行筛选，得出更优的物化视图。
2. 何时更新物化视图？如果在原始表更新的同时，也更新物化视图，可能会造成一些工作量的浪费。我这边的更新策略是在用到该视图的时候，对视图的更新时间和原始表的更新时间做对比，如果原始表的更新时间更晚，那么这时需要对物化视图进行更新。
3. 对于如何改写，业界已经有过不少讨论，还出过一些论文，例如[这篇](https://courses.cs.washington.edu/courses/cse591d/01sp/opt_views.pdf)。本项目也是参考了论文的理论部分。

## 项目结构

- Spark日志解析模块
- AI推荐模块
- Spark视图改写模块

## 项目实现

项目是开源的，先提供代码仓：[gitee仓库](https://gitee.com/reflectt6/boostkit-bigdata/commits/main)

Spark日志解析主要是调用Spark日志类的一些api加上直接对Spark打印的Log文本的清洗，得到实际的执行计划。

AI推荐模块由浙大同学使用强化学习完成。

我这边主要实现Spark改写模块，下面对此做详细介绍：

该模块可以细分为以下子模块：

- 命令解析模块：因为物化视图是我们新支持的特性，原生的spark sql没有相关的命令。我们沿用了spark内部的命令解析方式，定义了antlr4框架的g4文件（idea中安装antlrv4插件）
- 物化视图改写模块（新增了Spark中用于优化执行计划的Rule，通过我们自定义的Rule，替换相应的逻辑执行计划）

这两个模块通过Spark自带的SparkSessionExtensions注入到原生spark中

```scala
class OmniMV extends (SparkSessionExtensions => Unit) with RewriteLogger {
  override def apply(extensions: SparkSessionExtensions): Unit = {

    // OmniMV internal parser
    extensions.injectParser { case (spark, parser) =>
      new OmniMVExtensionSqlParser(spark, parser)
    }
    // OmniMV optimizer rules
    extensions.injectPostHocResolutionRule { (session: SparkSession) =>
      OmniMVOptimizerRule(session)
    }
  }
}
```

这两个子模块都比较复杂，下面简单来讲讲，有时间再完善一下。

### 物化视图改写模块（主要参考calcite）

根据不同的逻辑计划结构，应用不同的物化视图改写策略，这部分主要在MVRewriteRule的tryRewritePlan中。

找到了对应的改写策略，则就要进行逻辑计划的改写了，通用的改写逻辑在AbstractMaterializedViewRule类中，大致的流程为：

1. 检查视图元数据是否为空

2. 提取查询的逻辑计划和查询用到的表

3. 解析当前的候选视图（外层调用会遍历所有可以用的物化视图，每一个可用的物化视图会作为参数传到这个类中）

   ```scala
   // 4.iterate views,try match and rewrite
   val (viewName, srcViewTablePlan, srcViewQueryPlan) = candidateViewPlan
   ```

4. 检查此候选视图是否合法（这里要检查是因为AbstractMaterializedViewRule是一个抽象类，他的子类包括JoinRule、AggregateRule、OuterJoinRule等，每一个子类对于改写的要求是不同的，这里就是根据他是哪一个子类去判断此候选视图是否符合改写要求）

5. 将候选视图中的Attribute换成QueryPlan中的Attribute

6. 从视图元数据中获取这个候选视图对应的数据表，如果这些数据表不是QueryTables的子集，则此视图无法使用。

   否则将QueryTables减去候选视图对应的数据表得到需要给查询补偿的数据表。下面对这个候选视图做表补偿。（说明这个视图是查询sql的一个子集，需要在这个视图外面嵌套project去构造成和查询一样的结构）

7. 提取查询sql的谓词：主要实现见下文

8. 计算谓词补偿：对候选视图也做一个谓词提取，然后对比视图的谓词和查询的谓词。符合某种条件，则对视图做谓词补偿。否则该视图无法应用于本次查询，直接返回。



## 谓词提取

为了方便作谓词计算，我们需要提取候选视图和查询sql的执行计划的谓词，根据论文，我们把谓词分成三类：

- 等价谓词
- 范围谓词
- 其他谓词

对于以上三类谓词的计算，我参考了hive中的calcite组件，他是专门为谓词计算而生的。通过我写的Simplify静态类，可以方便的对这三类谓词做比较，例如对于范围谓词，比较哪一个范围更大等等。。

## 视图更新与淘汰

更新策略：在逻辑计划被视图改写成功之后，确认视图是否过期，如果过期则进行视图更新。

淘汰策略：

1. 根据视图使用次数从大到小排序（次数一样则根据时间戳，从大到小排序），保留结果的前N项（N可配置）

   命令：WASH OUT MATERIALIZED VIEW USING RESERVE_QUANTITY_BY_VIEW_COUNT $(NUM)

2. 删除距离上一次使用大于等于N天的视图（N可配置）

   命令：WASH OUT MATERIALIZED VIEW USING UNSED_DAYS $(NUM)

3. 删除占用空间最大的前N项，N可配置

   命令：WASH OUT MATERIALIZED VIEW USING DROP_QUANTITY_BY_SPACE_CONSUMED $(NUM)

4. 删除所有视图

   命令：WASH OUT ALL MATERIALIZED VIEW

说明：

1. 视图的使用次数、使用时间被落盘在hdfs上，路径可通过配置项配置

   ```scala
   def metadataPath: String = conf
         .getConfString("spark.sql.omnimv.metadata.path", "/user/omnimv/metadata")
   ```

2. 如果不加淘汰选项，默认淘汰最近30天没有使用的视图

   ```scala
   def minimumUnusedDaysForWashOut: Int = conf
         .getConfString("spark.sql.omnimv.washout.unused.day", "30")
         .toInt
   ```

[提交在这里](https://gitee.com/reflectt6/boostkit-bigdata/commit/d2292fd019be748a32a9e396e82f22f7672eab5c)

### 解决视图元数据在多session情况下，不同步的问题

如果你开两个spark-sql agent，对其中一个agent执行淘汰操作。再对另外一个agent执行淘汰操作，会因为第二个agent的元数据没有更新，得到旧的数据，导致报错。

这是因为视图的ViewMetadata是一个Object，每个agent都有自己的ViewMetadata对象，一个agent更新了ViewMetadata，并不会通知其他agent去更新。

为了解决这个问题，我实现一个分布式的文件锁。原理就是在hdfs上创建锁文件，其他agent发现这个锁文件存在，就说明有其他的agent在更新元数据。那么这个agent就自旋等待，直到锁文件消失或者超时。

通过这个分布式文件锁，可以实现分布式的原子操作。

将对视图使用次数等修改定为一个原子操作，这样每次在对视图使用次数等作修改时，先获取锁，然后比较一个自己ViewMetadata对象的修改时间和集群上的修改时间是否一致，如果不一致，则先更新自身，再对使用次数等作修改，改动之后进行落盘。

这样就解决了多个session并发修改元数据文件的问题，以及agent之间信息不同的问题。

[提交在这里](https://gitee.com/reflectt6/boostkit-bigdata/commit/c12116b60f188585e58927636b96643272f892fa)





