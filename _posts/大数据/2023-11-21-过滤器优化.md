---
layout: page-with-sidebar-math
title:  "过滤器优化"
date:   2023-11-23 10:47:03 +0800
author: reflectt6
categories: "大数据"
#permalink: 
mainTag: "大数据"
secondaryTag: "预研"
---

## [XOR Filter](https://arxiv.org/abs/1912.08258)

业界如Lindorm，曾将Bloom Filter替换为Ribbon Filter提升缓存命中率。Ribbon Filter是由Xor Filter优化而来。所以Xor Filter需要作为前置条件理解一下。

但是看了知乎、CSDN好几篇帖子，写的相当抽象，我就不给引用了。说他们写的不认真吧，还画了很多图；说他们写的认真吧，细节很多错误；并且很多段落是一样的，感觉都是互相抄的；理解上的易错点也没有讲出来，看完还是云里雾里的。

无奈Google到了[论文](https://arxiv.org/pdf/1912.08258.pdf)，自己啃一遍吧。啃论文是真不容易，但是啃完也是能懂得。主要是结合伪代码理解，豁然开朗。突然想到某人说的，`talk is cheap，show me the code`，所以就是说这些论文在bb什么，直接给代码不就完事了吗。。

几个理解上的关键难点：

### 论文里面那些符号怎么理解？

![image-20231121160157285](/assets/images/2023-11-21-过滤器优化//image-20231121160157285.png)

> U：表示所有可能作为Filter输入的元素
>
> S：表示你要对哪一个集合构建过滤器，Bloom过滤器需要提前构造，需要把已知的数据映射到过滤器中。这个提前构造可能很多人没概念。
>
> \|S\|：目标集合的大小
>
> B：Xor过滤器最终存在形态就是这么一个数组，数组里面存的是k位的数值
>
> c = \|B\|：过滤器的长度，论文建议长度由(1.23*\|S\|)+23计算得来
>
> fingerprint：也是个hash函数，可以将U中任意元素，映射为一个固定长度为k位的数值。实现上可以参考：比如把任意元素分成三组，3的机器码为11，因此你总可以得到固定长度为2位的数值。例如1对应01，2对应10，3对应11。
>
> h1、h2、h3:三个hash函数，分别将U中的元素映射到[0, c/3]、[c/3, 2c/3]、[2c/3, c]

### 如何构造Xor FIlter

主要看以下三个伪代码：Algorithm2、3、4

![image-20231121163234079](/assets/images/2023-11-21-过滤器优化//image-20231121163234079.png)

下面这个Algorithm 3 有几率失败。

![image-20231121163506675](/assets/images/2023-11-21-过滤器优化//image-20231121163506675.png)

论文给出了失败的概率统计

![image-20231121163601434](/assets/images/2023-11-21-过滤器优化//image-20231121163601434.png)

![image-20231121163643314](/assets/images/2023-11-21-过滤器优化//image-20231121163643314.png)

### 如何判断元素是否存在？

![image-20231121163727997](/assets/images/2023-11-21-过滤器优化//image-20231121163727997.png)

### 为什么这样的算法可以用来判断元素存在？

首先我们需要了解异或运算本身的性质

异或运算有：

1、交换律

2、结合律

3、两个相同数xor的结果总为0

4、任何数和0 xor总为数本身

Algorithm2、3、4这三个算法保证了：

`对于任意的数x, B[h0(x)]、B[h1(x)]、B[h2(x)]中有且仅有一个apply了Algorithm4中的下面的赋值语句`

至于为什么能保证，请结合算法本身理解，这一部分的理解可以参考[知乎里面的图解](https://zhuanlan.zhihu.com/p/543943112)

![image-20231121165802686](/assets/images/2023-11-21-过滤器优化//image-20231121165802686.png)

假如只有B[h0(x)] apply 了上面的赋值语句，也就是i=h0(x)的情况，有 

`B[h0(x)] xor B[h1(x)] xor B[h2(x)] `

 `= `

 `(fingerprint(x) xor B[h0(x)] xor B[h1(x)] xor B[h2(x)]) `

`xor B[h1(x)]`

`xor B[h2(x)]`

`=`

`fingerprint(x) xor B[h0(x)] xor B[h1(x)] xor B[h2(x)] xor B[h1(x)] xor B[h2(x)]`

`=`

`fingerprint(x) xor B[h0(x)]`

`=fingerprint(x)    #由于i=h0(x)，所以B[h0(x)]被赋值为0；`



## [Ribbon Filter](https://arxiv.org/abs/2103.02515)

[论文](https://arxiv.org/pdf/2103.02515.pdf)

这论文比xor filter难懂的多，可以适当参考[知乎](https://zhuanlan.zhihu.com/p/565523164)大佬的分析

一个r位数，每个位可能的取值为0或者1: $$ \{0,1\}^r $$

异或: $$\bigoplus$$

同或: $$\bigodot$$



看知乎上说Ribbon Filter用的是高斯消元，而Rox Filter用的是Peeling，什么是Peeling？这个也是论文里面定义的，原文如下：

`Standard Xor filters use a fast solving process called peeling that limits their space efficiency to ≥ 1.22𝜆 bits per key7`

#### 论文概述

Section 2

简短的回顾了“static functions”，这个和java中的静态方法不是一个东西。作者想通过“static functions”定义一个过滤器

Section 3

分析Ribbon的构造算法；提出一个提升空间效率的优化“smash”；这些特性会导致，key数量上升的同时，空间或者时间开销上升。

Section 4

提出Homogeneous Ribbon filter，和Blocked bloom filter 共享许多参数。优点为：1、构造的成功性是可以保证的 2、扩展至任意的key数量，都是高效的

实现简单，但是要分析更多

Section 5

描述一些实验性的问题：

1、有效利用任意key数量的内存

2、高效查询的数据分布

3、高效满足hash需求

4、扩展标准Ribbon通过数据共享

Section 6

提出Balanced ribbon，通过连续ribbon，贪婪的加载balancing表。极大优化了“smash”的ribbon空间效率。

Section 7

更多实验验证。



#### Section3

从“静态方法（没啥实际含义，当个称呼就行）”构建ribbon过滤器

这个“静态方法”来自一篇[论文](https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.ESA.2019.39)，通过矩阵高效求解高斯消元问题。

ribbon过滤器实际上就是这个高斯方法的应用。

[论文PDF](https://drops.dagstuhl.de/storage/00lipics/lipics-vol144-esa2019/LIPIcs.ESA.2019.39/LIPIcs.ESA.2019.39.pdf)，挺离谱的，一个图都没有，全是字！

然后用图文给出了ribbon构造算法。

介绍了ribbon的一种错误场景（没看懂），以及解决思路。



#### Section4

HOMOGENEOUS RIBBON FILTERS是齐次ribbon过滤器的意思。就是线性代数里面齐次线性方程的齐次。也就是右侧的矩阵为0矩阵。齐次线性方程必有零解。



## [RocksDB](https://github.com/facebook/rocksdb)

Facebook团队开发的key-value类型的存储库，采用c++开发，封装JNI给Java代码提供服务，但是Java的接口可能是滞后的（因为没时间同步，推荐开发者自发提PR）。

与HBase很类似，都是支持任意大小的键值对。区别在于HBase专注于大数据生态。而RocksDB支持各种存储硬件，包括纯内存，闪存、硬盘、远程存储等。

RocksDB详细文档在[github wiki](https://github.com/facebook/rocksdb/wiki)上

如何使用在[这里](https://github.com/facebook/rocksdb/wiki/Basic-Operations)

如何使用Java接口在[这里](https://github.com/facebook/rocksdb/wiki/RocksJava-Basics)

编译构建在[这里](https://github.com/facebook/rocksdb/blob/main/INSTALL.md)

### 源码分析

#### UT起手

从UT入手，关于ribbon filter的UT入口在ribbon_test.cc文件中。用到了gtest测试框架

gtest本质上做的事情就是将测试内容作为参数传递，例如测试的数据类型作为参数，测试数据作为参数

```c++
using TestTypesAndSettings = ::testing::Types<
    TypesAndSettings_Coeff128, TypesAndSettings_Coeff128Smash,
    TypesAndSettings_Coeff64, TypesAndSettings_Coeff64Smash,
    TypesAndSettings_Coeff64Smash0, TypesAndSettings_Coeff128_Homog,
    TypesAndSettings_Coeff128Smash_Homog, TypesAndSettings_Coeff64_Homog,
    TypesAndSettings_Coeff64Smash_Homog, TypesAndSettings_Result16,
    TypesAndSettings_Result32, TypesAndSettings_IndexSizeT,
    TypesAndSettings_Hash32, TypesAndSettings_Hash32_Result16,
    TypesAndSettings_KeyString, TypesAndSettings_Seed8,
    TypesAndSettings_NoAlwaysOne, TypesAndSettings_AllowZeroStarts,
    TypesAndSettings_Seed64, TypesAndSettings_Rehasher,
    TypesAndSettings_Rehasher_Result16, TypesAndSettings_Rehasher_Result32,
    TypesAndSettings_Rehasher_Seed64, TypesAndSettings_Rehasher32,
    TypesAndSettings_Rehasher32_Coeff64, TypesAndSettings_SmallKeyGen,
    TypesAndSettings_Hash32_SmallKeyGen, TypesAndSettings_Coeff32,
    TypesAndSettings_Coeff32Smash, TypesAndSettings_Coeff16,
    TypesAndSettings_Coeff16Smash>;
TYPED_TEST_CASE(RibbonTypeParamTest, TestTypesAndSettings);
```

TYPED_TEST_CASE应该是注册了测试的数据类型。

```c++
TYPED_TEST(RibbonTypeParamTest, CompactnessAndBacktrackAndFpRate) {
  IMPORT_RIBBON_TYPES_AND_SETTINGS(TypeParam);
  IMPORT_RIBBON_IMPL_TYPES(TypeParam);
  using KeyGen = typename TypeParam::KeyGen;
  using ConfigHelper =
      ROCKSDB_NAMESPACE::ribbon::BandingConfigHelper<TypeParam>;
  。。。。
```

注册完之后，下面对于RibbonTypeParamTest的测试应该就会将上面所有类型都跑一遍，也就是别看这只是一个UT，但实际上会测几十种类型，也是框架的能力所在。而CompactnessAndBacktrackAndFpRate应该类似Java UT中的case name。

既然找到了UT，下一步就是找Ribbon filter的实现。换位思考，如果我写了一个Ribbon filter 我会写什么样的UT来测？

​	1、Ribbon filter目的在节省内存空间，那么我一定要对比这个filter和bloom filter的占用空间

​	2、对比ribbon和bloom的构建时间。。（可能）

​	3、随机生成一下query，查看Fp rate(错误率)，并且和bloom对比

那再看下实际上有哪些测试内容，据我的测试TYPED_TEST会apply上面那注册的一堆类型，但是TEST不会，只会运行一次。

```c++
//1、测试各种类型
TYPED_TEST(RibbonTypeParamTest, CompactnessAndBacktrackAndFpRate) // 压缩率和错误率

TYPED_TEST(RibbonTypeParamTest, Extremes) // 极端情况？

// Not a real test, but a tool used to build APIs in ribbon_config.h
TYPED_TEST(RibbonTypeParamTest, FindOccupancy)

// Not a real test, but a tool to understand Homogeneous Ribbon
// behavior (TODO: configuration APIs & tests)
TYPED_TEST(RibbonTypeParamTest, OptimizeHomogAtScale) // 这玩意是理解Homogeneous Ribbon的工具？
```

关注的变量有哪些？分别对应算法中的什么值？

```c
TEST(RibbonTest, AllowZeroStarts) // 允许以0开头，那么是什么的开头呢？

TEST(RibbonTest, RawAndOrdinalSeeds) // 原始的种子 测试，种子是干什么的？ 生成Hash？

TEST(RibbonTest, PhsfBasic) // phsf是啥？
```

ok，这名字起的非常好，看似没啥用，实则一点用没有。

两个关键宏

```c++
IMPORT_RIBBON_TYPES_AND_SETTINGS(TypeParam);
IMPORT_RIBBON_IMPL_TYPES(TypeParam);
```

第一个宏可以得到ribbon filter关注的变量有哪些

```
CoeffRow
ResultRow
Index
Hash
Key
Seed

/* Some more additions */    
QueryInput
AddInput
kCoeffBits

/* Export to algorithm */
kFirstCoeffAlwaysOne 
```

第二个宏，可以得到ribbon filter实现所需要的几个关键对象

```
using Hasher = ROCKSDB_NAMESPACE::ribbon::StandardHasher<TypesAndSettings>;
using Banding = ROCKSDB_NAMESPACE::ribbon::StandardBanding<TypesAndSettings>;    
using SimpleSoln = ROCKSDB_NAMESPACE::ribbon::InMemSimpleSolution<TypesAndSettings>;
using InterleavedSoln = ROCKSDB_NAMESPACE::ribbon::SerializableInterleavedSolution<TypesAndSettings>;
```

把上面这几个参数和对象搞明白ribbon filter基本上可以搞定

#### ribbon相关代码

从UT入手可以得到几个ribbon相关的代码文件

- ribbon_impl.h
- ribbon_alg.h
- ribbon_config.h

#### Hasher

`StandardHasher: A standard implementation of concepts RibbonTypes, PhsfQueryHasher, FilterQueryHasher, and BandingHasher from ribbon_alg.h.`

从这个注释可以看出什么？首先ribbon是有不同类型的，目前起码有三种PhsfQueryHasher、 FilterQueryHasher、 and BandingHasher。他们的实现在ribbon_alg.h中

关于 Hasher的注释，translated by chatGpt 3.5

```
这个实现在大多数实际情况下应该是合适的，因为它在各种设置下都能够“表现”良好，几乎没有改进的余地。在这个哈希函数中的关键功能是从一个适度的64位或者仅仅32位的哈希中生成CoeffRows、starts和（对于过滤器而言）ResultRows，这可能是150位甚至更多的数据，具有足够的均匀性和位独立性，以接近在FP率和紧凑性方面利用可用哈希信息“做到最好”的水平。（对于PHSF的实际目的，推荐使用64位并且足够。）

这个哈希函数的另一个特性是在将种子提供给TypesAndSettings::HashFn之前进行最小程度的“预混合”，以防该函数在仅按顺序迭代种子时无法提供足够独立的哈希值。 （例如，这可以解决RocksDB中使用的XXH3预览版本0.7.2存在的问题，即XXPH3或Hash64，以及RocksDB中使用的MurmurHash1，即Hash）。我们称这个预混合步骤将“序数种子”（我们按顺序迭代以找到解决方案的种子）转换为“原始种子”，在每次迭代中有更多的位发生变化。这种转换是一种易于逆转的轻量级混合，不适合单独进行哈希。这种方法的优势在于StandardHasher可以仅存储原始种子（例如64位），以实现快速查询时间，而从应用程序的角度来看，我们可以限制保存在元数据中的序数键数量（例如6位中的64个）。

默认构造函数将种子初始化为序数种子零，这与原始种子零相等。
```

#### Banding

```
tandardBanding: a canonical implementation of BandingStorage and BacktrackStorage, with convenience API for banding (solving with on-the-fly Gaussian elimination) with and without backtracking.
 
StandardBanding：是BandingStorage和BacktrackStorage的经典实现，提供了带有和不带有回溯的带宽（通过即时高斯消元求解）的便利API。
```

那么问题来了， BandingStorage和BacktrackStorage是什么？

replied by chat gpt：

```
BandingStorage和BacktrackStorage是与算法和数据结构相关的概念，通常在解决问题时用于存储和处理中间结果。

BandingStorage（带宽存储）：

定义： 用于在解决问题时存储和处理带宽的数据结构。
用途： 在某些算法中，带宽是指一组值或范围，用于描述问题的特定方面。BandingStorage通常用于存储这些带宽，并提供一种有效的方式进行操作和查询。
BacktrackStorage（回溯存储）：

定义： 用于在解决问题时存储和处理回溯信息的数据结构。
用途： 在问题解决过程中，有时需要回溯（即返回之前的状态）以尝试不同的路径或选择。BacktrackStorage用于记录在解决问题时所做的选择，以便在需要时能够回退到之前的状态，重新探索其他可能的解决方案。
这些概念通常与特定的算法或问题领域相关联，因此具体的实现和用途可能会根据上下文而异。在你提供的文本中，这些概念可能是用于某种解决方案的关键组件，涉及到带宽和回溯的存储和处理。
```



#### InMemSimpleSolution

```
 Implements concept SimpleSolutionStorage, mostly for demonstration
 purposes. This is "in memory" only because it does not handle byte
 ordering issues for serialization.
 
 
实现SimpleSolutionStorage概念，主要用于演示目的。这仅仅是“内存中”的，因为它不处理序列化的字节顺序问题。
```

那么问题来了，SimpleSolutionStorage是什么？这个chat gpt也不懂，开始分析了一波

```
SimpleSolutionStorage 是一个概念或者接口，用于表示一种存储解决方案的简单实现。根据提供的上下文，它可能是用于存储问题解决方案的数据结构或接口的一部分。

以下是对文本中提到的 SimpleSolutionStorage 的翻译：

实现了 SimpleSolutionStorage 概念，主要用于演示目的。这仅仅是“内存中”的，因为它不处理序列化的字节顺序问题。

这段文字表明 SimpleSolutionStorage 作为一个概念被实现，主要用于演示。它被描述为一种在内存中存储解决方案的简单实现，并且由于不涉及处理序列化的字节顺序问题，它被限定为“内存中”使用，即在内存中操作而不涉及外部存储或网络传输。

在具体的上下文中，SimpleSolutionStorage 的实现可能包括存储解决方案的数据结构，以及用于查询、更新或处理解决方案的相关方法。
```



#### SerializableInterleavedSolution

```
 Implements concept InterleavedSolutionStorage always using little-endian
 byte order, so easy for serialization/deserialization. This implementation
 fully supports fractional bits per key, where any number of segments
 (number of bytes multiple of sizeof(CoeffRow)) can be used with any number
 of slots that is a multiple of kCoeffBits.

 The structure is passed an externally allocated/de-allocated byte buffer
 that is optionally pre-populated (from storage) for answering queries,
 or can be populated by BackSubstFrom.
 
实现InterleavedSolutionStorage概念，始终使用小端字节顺序，因此便于序列化和反序列化。这个实现完全支持每个键的分数位，其中可以使用任意数量的段（字节数是CoeffRow的sizeof倍数）以及任意数量的插槽（是kCoeffBits的倍数）。

该结构接收一个外部分配/释放的字节缓冲区，可选择地预先填充（从存储中）以回答查询，或者可以由BackSubstFrom填充。
```

那么问题来了，InterleavedSolutionStorage是什么？

根据分析，interleaved是一种高效的存储格式，类似列式存储。



#### ribbon_alg.h

核心算法的通用版本，聚焦核心细节

```
ribbon是一个完美的静态hash方法，结合一下优点
1、布尔线性系统
2、增量，即时的高斯消元法
3、高效的存储方式
```



#### ribbon_impl.h



#### PHSF

如果我没猜错的话，应该是`A Perfect Hash Static Function`的缩写，作用是

`A Perfect Hash Static Function is a data structure representing a map from anything hashable (a "key") to values of some fixed size.`

更重要的是：

`Crucially, it is allowed to return garbage values for anything not in the original set of map keys`

而且构建好之后，它的entries就不能再增加或者删除了



#### entry

猜测entry就是构建过滤器用的row

