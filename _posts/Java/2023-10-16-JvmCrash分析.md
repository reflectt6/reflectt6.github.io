---
layout: page-with-sidebar
title:  "JVMCrash分析"
date:   2023-10-16 15:47:03 +0800
author: reflectt6
categories: "编程基础"
mainTag: "编程基础"
secondaryTag: "Java"
hideTag: false
---

## 背景

工作中遇到了一个java虚拟机crash的场景，随即定位了一下crash原因。虽然没有定位出来，但是用到一些新知识，记录一下，为以后的分析打点基础。也会讲下为什么没有定位出来。

crash的场景发生在[HBase二级索引](/项目回顾/2023/09/20/hbase二级索引.html#tocAnchor-4-1-2)的大项目背景下，在解决并发问题的小章节中。我写了一个UT，并发运行对hbase数据表同一行的修改，希望能保证二级索引表可以在并发情况下和数据表也能保持一致。crash就发生在这个UT中，我设置了100并发，UT运行不会出错。但是我增加并发数到150及以上，UT运行1min左右发生VM crash。

## 查看VM日志

当VM奔溃之后，一般会生成一个hs_err_pidxxx.log的日志文件，他就是我要分析的对象。

先找篇[帖子](https://blog.csdn.net/chenssy/article/details/78271744)学习一下，这篇帖子比较细致的对该日志文件做了介绍。

### 分析一

其中的 `Problematic frame:`信息据说比较重要。而我的日志文件中，这里给出了出错的对应类和方法名。然后我又横向对比了其他几个错误日志（UT跑了很多次，所以有多个日志文件）。发现 `Problematic frame:`这里的类名和方法名有很多，每次似乎是随机的。

所以我分析，他并非是java层面出的问题，可能是jvm层面的问题（导致jvm出问题的可能是一些后台java线程，这个我后面讲），因此在jvm出问题的时候，java主线程走到哪里是不确定的，这就是每次 `Problematic frame:`不一样的原因。

### 分析二

Current Thread也是比较重要的，它指出了现在出问题的线程是哪一个。例如这次，我这边的线程是 `RpcServer.default.FPBQ.Fifo.handler=3,queue=0,port=52266`。可以看到出问题的是一个RpcServer的线程，这就大大加大了定位问题的难度。我们项目使用了gRpc实现远程方法调用，对于这个RPC框架的了解仅仅是如何使用，当框架内的线程引发问题的时候，往往这个问题是无从下手的。

由于是Rpc线程出了问题，所以在分析一中，我说 `导致jvm出问题的可能是一些后台java线程`。这个后台java线程就是rpc请求，在并发情况下，很多的rpc请求也在并发执行，每个rpc请求相当于一个后台线程，在不断等待回应。出问题的线程可能是他们中的某一个，在某种条件下，导致jvm崩溃了。

如果要进一步去寻找问题，可能要熟悉gRPC的代码，找到出问题的线程堆栈。本错误日志中，没有堆栈信息，对比下[csdn的帖子](https://blog.csdn.net/chenssy/article/details/78271744)，我的错误日志里没有java frames。

![image-20231016185210126](/assets/images/2023-10-16-JVMCrash分析//image-20231016185210126.png)

由于以上原因导致分析无法继续下去了。。。











